# 📦 Imports
from pathlib import Path
from langchain.text_splitter import RecursiveCharacterTextSplitter

# 📂 Load raw text file
input_path = Path("InFloBook.txt")
with open(input_path, "r", encoding="utf-8") as f:
    raw_text = f.read()

# 🔍 Preview
#print(raw_text[2000:5000])


# 🧼 Remove empty lines and extra whitespace
cleaned_text = "\n".join([line.strip() for line in raw_text.splitlines() if line.strip()])
print(f"🧼 Cleaned text length: {len(cleaned_text)} characters")
#print(cleaned_text[3000:5000])


#creat text chunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ".", "!", "?", " ", ""]
)

chunks = text_splitter.split_text(cleaned_text)
print(f"🔪 Total chunks created: {len(chunks)}")
print("🧩 First chunk preview:\n", chunks[0])



import json
from pathlib import Path

output_path = Path("../data/processed/chunks_InFlowBook.json")
output_path.parent.mkdir(parents=True, exist_ok=True)

with open(output_path, "w", encoding="utf-8") as f:
    json.dump(chunks, f, ensure_ascii=False, indent=2)

print(f"✅ Chunks saved to: {output_path}")




